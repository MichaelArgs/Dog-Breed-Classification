{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM99u/ylqaI/llk9Jp5He+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelArgs/Dog-Breed-Classification/blob/main/dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instal Streamlit\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuycSiM-m-EU",
        "outputId": "b7199ddf-2726-4a26-84d3-367fc841c5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.39.0 watchdog-5.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang dibutuhkan untuk deep learning, pengolahan gambar, dan Streamlit\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import json\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "j9OFGwhmhWV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset yang berisi gambar jenis anjing\n",
        "zip_path = '/content/70 dog breed.zip'  # Path ke file zip dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/70 dog breed')  # Ekstraksi ke folder"
      ],
      "metadata": {
        "id": "7tJXTmAyWBU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan path untuk data pelatihan, validasi, dan pengujian\n",
        "train_path = '/content/70 dog breed/train'\n",
        "valid_path = '/content/70 dog breed/valid'\n",
        "test_path = '/content/70 dog breed/test'"
      ],
      "metadata": {
        "id": "C46cxhpBh91t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation untuk memperbanyak variasi data pelatihan\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Normalisasi nilai pixel antara 0 dan 1\n",
        "    rotation_range=40,           # Rotasi gambar hingga 40 derajat\n",
        "    width_shift_range=0.2,       # Pergeseran lebar hingga 20%\n",
        "    height_shift_range=0.2,      # Pergeseran tinggi hingga 20%\n",
        "    shear_range=0.2,             # Distorsi gambar (shear) hingga 20%\n",
        "    zoom_range=0.3,              # Zoom gambar hingga 30%\n",
        "    horizontal_flip=True,        # Flip horizontal untuk variasi\n",
        "    fill_mode='nearest'          # Mode pengisian pixel kosong\n",
        ")\n",
        "\n",
        "# Hanya rescale untuk data validasi\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Membuat generator data untuk pelatihan dan validasi\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(128, 128),      # Ubah ukuran gambar ke 128x128 pixel\n",
        "    batch_size=32,               # Jumlah gambar per batch\n",
        "    class_mode='categorical'     # Mode klasifikasi untuk lebih dari 2 kelas\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJt2u8Jqn3mG",
        "outputId": "b6713b63-2063-412c-ec65-94642ca1216b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7946 images belonging to 70 classes.\n",
            "Found 700 images belonging to 70 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model MobileNetV2 sebagai base model dengan bobot ImageNet\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Membuka lapisan terakhir untuk fine-tuning\n",
        "for layer in base_model.layers[-50:]:  # Buka 50 lapisan terakhir untuk pelatihan\n",
        "    layer.trainable = True\n",
        "\n",
        "# Menambahkan lapisan tambahan di atas base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)    # Pooling global untuk meratakan fitur\n",
        "x = Dense(512, activation='relu')(x)  # Lapisan Dense dengan 512 unit\n",
        "x = Dropout(0.5)(x)                # Dropout untuk mengurangi overfitting\n",
        "output = Dense(train_generator.num_classes, activation='softmax')(x)  # Lapisan output untuk klasifikasi\n",
        "\n",
        "# Definisikan model lengkap dengan MobileNetV2 dan lapisan tambahan\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilasi model dengan optimizer Adam dan learning rate kecil\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTiA6ml9ndhX",
        "outputId": "ef2d6bb4-e9dd-47fd-a2ec-746666863237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup callback untuk checkpoint, early stopping, dan pengurangan learning rate\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"model_checkpoint.weights.h5\",  # Menyimpan checkpoint setiap epoch\n",
        "    save_weights_only=True,                  # Menyimpan hanya bobot model\n",
        "    save_freq='epoch',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# EarlyStopping untuk menghentikan pelatihan jika tidak ada peningkatan dalam 5 epoch\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Mengurangi learning rate jika tidak ada peningkatan dalam 3 epoch\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Kumpulan callbacks untuk pelatihan\n",
        "callbacks = [checkpoint_callback, early_stopping, reduce_lr]\n"
      ],
      "metadata": {
        "id": "qqReBz9x3eQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture (same as before)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Unfreeze some layers for fine-tuning\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load the saved weights\n",
        "model.load_weights(\"model_checkpoint.weights.h5\")\n",
        "print(\"Weights loaded from the last checkpoint.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "nkgnUgY5_d8T",
        "outputId": "c215efad-bad6-44bb-f050-aa0c053284c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-8ad276bba60d>:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Dense name=dense_2, built=False> (of type <class 'keras.src.layers.core.dense.Dense'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8ad276bba60d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 ):\n\u001b[0;32m--> 789\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    790\u001b[0m                         \u001b[0;34m\"Only input tensors may be passed as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                         \u001b[0;34m\"positional arguments. The following argument value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Dense name=dense_2, built=False> (of type <class 'keras.src.layers.core.dense.Dense'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model menggunakan generator data pelatihan dan validasi\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=30,                      # Jumlah epoch\n",
        "    callbacks=callbacks              # Memasukkan callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL-9McfSoLND",
        "outputId": "daa3df34-c021-468c-ebc5-9781f5490473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1130 - loss: 3.9646\n",
            "Epoch 1: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2s/step - accuracy: 0.1136 - loss: 3.9615 - val_accuracy: 0.6429 - val_loss: 1.3617 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5278 - loss: 1.7542\n",
            "Epoch 2: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 2s/step - accuracy: 0.5280 - loss: 1.7534 - val_accuracy: 0.7029 - val_loss: 1.1334 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6737 - loss: 1.1569\n",
            "Epoch 3: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 2s/step - accuracy: 0.6737 - loss: 1.1569 - val_accuracy: 0.7343 - val_loss: 1.0879 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7169 - loss: 0.9914\n",
            "Epoch 4: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 2s/step - accuracy: 0.7169 - loss: 0.9913 - val_accuracy: 0.7771 - val_loss: 0.8769 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7665 - loss: 0.7987\n",
            "Epoch 5: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 2s/step - accuracy: 0.7665 - loss: 0.7988 - val_accuracy: 0.8186 - val_loss: 0.8196 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7806 - loss: 0.7590\n",
            "Epoch 6: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 0.7806 - loss: 0.7590 - val_accuracy: 0.8429 - val_loss: 0.7289 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7910 - loss: 0.6891\n",
            "Epoch 7: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 2s/step - accuracy: 0.7910 - loss: 0.6891 - val_accuracy: 0.8614 - val_loss: 0.6960 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8101 - loss: 0.6239\n",
            "Epoch 8: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 2s/step - accuracy: 0.8101 - loss: 0.6239 - val_accuracy: 0.8614 - val_loss: 0.6580 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.5772\n",
            "Epoch 9: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.5773 - val_accuracy: 0.8543 - val_loss: 0.7341 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8351 - loss: 0.5545\n",
            "Epoch 10: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 2s/step - accuracy: 0.8351 - loss: 0.5545 - val_accuracy: 0.8286 - val_loss: 0.8140 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8419 - loss: 0.5191\n",
            "Epoch 11: saving model to model_checkpoint.weights.h5\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.8419 - loss: 0.5192 - val_accuracy: 0.8400 - val_loss: 0.8087 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8648 - loss: 0.4439\n",
            "Epoch 12: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 2s/step - accuracy: 0.8649 - loss: 0.4438 - val_accuracy: 0.8914 - val_loss: 0.6150 - learning_rate: 2.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8704 - loss: 0.4152\n",
            "Epoch 13: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 2s/step - accuracy: 0.8704 - loss: 0.4152 - val_accuracy: 0.8971 - val_loss: 0.5938 - learning_rate: 2.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8825 - loss: 0.3883\n",
            "Epoch 14: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 2s/step - accuracy: 0.8825 - loss: 0.3882 - val_accuracy: 0.9057 - val_loss: 0.5793 - learning_rate: 2.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8979 - loss: 0.3321\n",
            "Epoch 15: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 2s/step - accuracy: 0.8979 - loss: 0.3322 - val_accuracy: 0.9114 - val_loss: 0.5515 - learning_rate: 2.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8975 - loss: 0.3473\n",
            "Epoch 16: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 2s/step - accuracy: 0.8975 - loss: 0.3473 - val_accuracy: 0.9171 - val_loss: 0.5269 - learning_rate: 2.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8900 - loss: 0.3585\n",
            "Epoch 17: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 2s/step - accuracy: 0.8900 - loss: 0.3584 - val_accuracy: 0.9200 - val_loss: 0.5101 - learning_rate: 2.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8914 - loss: 0.3372\n",
            "Epoch 18: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 2s/step - accuracy: 0.8914 - loss: 0.3371 - val_accuracy: 0.9257 - val_loss: 0.5129 - learning_rate: 2.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9045 - loss: 0.3048\n",
            "Epoch 19: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 2s/step - accuracy: 0.9045 - loss: 0.3049 - val_accuracy: 0.9271 - val_loss: 0.5086 - learning_rate: 2.0000e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9053 - loss: 0.2998\n",
            "Epoch 20: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 2s/step - accuracy: 0.9052 - loss: 0.2999 - val_accuracy: 0.9186 - val_loss: 0.5409 - learning_rate: 2.0000e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9085 - loss: 0.3022\n",
            "Epoch 21: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 2s/step - accuracy: 0.9085 - loss: 0.3022 - val_accuracy: 0.9286 - val_loss: 0.5056 - learning_rate: 2.0000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9088 - loss: 0.2771\n",
            "Epoch 22: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 2s/step - accuracy: 0.9088 - loss: 0.2771 - val_accuracy: 0.9214 - val_loss: 0.5370 - learning_rate: 2.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9071 - loss: 0.2943\n",
            "Epoch 23: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 2s/step - accuracy: 0.9071 - loss: 0.2943 - val_accuracy: 0.9171 - val_loss: 0.5234 - learning_rate: 2.0000e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9080 - loss: 0.2803\n",
            "Epoch 24: saving model to model_checkpoint.weights.h5\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 2s/step - accuracy: 0.9080 - loss: 0.2803 - val_accuracy: 0.9157 - val_loss: 0.5294 - learning_rate: 2.0000e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9214 - loss: 0.2618\n",
            "Epoch 25: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 0.9214 - loss: 0.2618 - val_accuracy: 0.9243 - val_loss: 0.5225 - learning_rate: 4.0000e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9159 - loss: 0.2673\n",
            "Epoch 26: saving model to model_checkpoint.weights.h5\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 2s/step - accuracy: 0.9159 - loss: 0.2673 - val_accuracy: 0.9229 - val_loss: 0.5262 - learning_rate: 4.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model akhir setelah pelatihan\n",
        "model.save(\"dog_breed_classifier.h5\")\n",
        "\n",
        "# Unduh model yang sudah dilatih\n",
        "files.download(\"dog_breed_classifier.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt45aNYNhNNC",
        "outputId": "907be290-cd99-429e-957b-1fe8544a8bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan nama kelas (jenis anjing) ke dalam file JSON\n",
        "breed_names = train_generator.class_indices  # Mapping nama kelas ke indeks\n",
        "with open(\"class_indices.json\", \"w\") as f:\n",
        "    json.dump(breed_names, f)\n",
        "\n",
        "# Unduh file JSON yang berisi nama kelas\n",
        "files.download(\"class_indices.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_wpiElAXyNrz",
        "outputId": "7acb8a90-f3f0-490c-ce0e-bfc564ed7f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4bf70b4f-ab20-4fa2-aea3-ed550679cc4e\", \"class_indices.json\", 1212)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}